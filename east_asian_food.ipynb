{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Grocery Store should I go for East Asian Food? Logit Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep # control the crawl rate to avoid hammering the servers with too many requests\n",
    "from random import randint\n",
    "import re # regular expression\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import chromedriver_binary # adds chromedriver binary to path\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer #tokenizing the words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_pages(list_of_pages):\n",
    "    pages = []\n",
    "    for page in list_of_pages:\n",
    "        if pd.notnull(page):\n",
    "            all_pages = requests.get(page)\n",
    "            each_page = BeautifulSoup(all_pages.content, \"html.parser\")\n",
    "            pages.append(each_page)\n",
    "            sleep(randint(2,6))\n",
    "        else: \n",
    "            pages.append(None)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping H Mart Items for East Asian Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmart = ['https://www.hmart.com/groceries?p=' + str(i) for i in range(1,16)]\n",
    "hmart_parsed = parsing_pages(hmart)\n",
    "\n",
    "# finding item names from a list of beautifulsoup objects\n",
    "key = 'product name product-item-name'\n",
    "items = [] \n",
    "for page in hmart_parsed:\n",
    "    items_in_pages = page.find_all('strong', class_=key)\n",
    "    for item in items_in_pages: # cleaning up the messy text\n",
    "        items_per_page = item.get_text().replace('\\n','').replace('\\r','').strip().replace('     ', ' ').lower()\n",
    "        items.append(items_per_page)\n",
    "\n",
    "# extracting item names from the text\n",
    "brands = [i.split('        ')[0] for i in items]\n",
    "item_names = [i.split('        ')[-1] for i in items]\n",
    "\n",
    "# extracting volumns at the end\n",
    "regrex = re.compile(r'\\d\\..*')\n",
    "item_volumns = [regrex.findall(i) for i in item_names]\n",
    "\n",
    "## asian items with brand names\n",
    "asian_items = []\n",
    "for i, j in zip(brands, item_names):\n",
    "    asian_item = i + ' ' + j\n",
    "    asian_items.append(asian_item)\n",
    "\n",
    "# getting rid of texts about volumns \n",
    "asian_items_no_volumns = []\n",
    "for i in asian_items:\n",
    "    asian_item = re.sub(' \\d\\..*', '', i)\n",
    "    asian_items_no_volumns.append(asian_item)\n",
    "\n",
    "columns = {\n",
    "    'item_name': asian_items_no_volumns,\n",
    "    'item_volumn': item_volumns,\n",
    "    'type': 'asian'\n",
    "}\n",
    "asian_items = pd.DataFrame(data = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asian_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Walmart Items for Non-East Asian Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Walmart uses dynamic web pages, thus can't use BeautifulSoup\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.walmart.com/browse/food/\")\n",
    "\n",
    "list_of_items_from_pages = []\n",
    "for n in range(1,26):\n",
    "        driver.get(\"https://www.walmart.com/browse/food/?page=\" + str(n))\n",
    "        items_from_pages = driver.find_elements_by_css_selector(\".product-title-link.line-clamp span\")\n",
    "        for i in items_from_pages:\n",
    "            items_extracted = i.text\n",
    "            list_of_items_from_pages.append(items_extracted)\n",
    "        sleep(3)\n",
    "\n",
    "        \n",
    "# getting rid of units/volumns at the beginning of each item\n",
    "pack = re.compile(r'\\(\\d{1,} (?:pack|count|cans)\\)') \n",
    "list_of_items_from_pages = [re.sub(pack, '', i.lower()) for i in list_of_items_from_pages]\n",
    "\n",
    "# isolating volumns at the end\n",
    "regrex = re.compile(r'(?:, \\d{1,}|\\d{1,} (?:mg|oz|fl|ct)|, \\d{1,} (?:mg|oz|fl|ct)).*')\n",
    "walmart_item_volumns = [regrex.findall(i) for i in list_of_items_from_pages]\n",
    "walmart_item_names = [re.sub(regrex, '', i.split(',')[0].strip()) for i in list_of_items_from_pages]\n",
    "\n",
    "columns = {\n",
    "    'item_name': walmart_item_names,\n",
    "    'item_volumn': walmart_item_volumns,\n",
    "    'type': 'non-asian'\n",
    "}\n",
    "walmart_items = pd.DataFrame(data = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, concat the two lists together\n",
    "frames = [walmart_items, asian_items]\n",
    "df = pd.concat(frames).reset_index(drop = True)\n",
    "\n",
    "# seperate training and test sets\n",
    "from random import sample\n",
    "df_train = df.sample(frac=0.6, random_state=0)\n",
    "df_test = df.drop(df_train.index)\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english',max_df=0.85)\n",
    "train_vect = count_vect.fit_transform(df_train.item_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing/vectorizing the Item Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 1757)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "train_tf_transformer = TfidfTransformer(use_idf=False).fit(train_vect)\n",
    "train_tf = train_tf_transformer.transform(train_vect)\n",
    "train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679, 1757)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "test_vect = count_vect.transform(df_test.item_name) # not fitting, but transforming\n",
    "# test_tf_transformer = TfidfTransformer(use_idf=False).fit(train_vect)\n",
    "test_tf = train_tf_transformer.transform(test_vect)\n",
    "test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337260677466863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_tf\n",
    "y_train = df_train.type\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_tf\n",
    "y_test = df_test.type\n",
    "\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Wegmans and Harris Teeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wegmans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wegmans\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "wegmans_international_items = []\n",
    "driver.get(\"https://shop.wegmans.com/shop/categories/345?page=1\")\n",
    "sleep(3)\n",
    "driver.find_element_by_css_selector(\"#shopping-selector-shop-context-intent-instore\").click()\n",
    "sleep(3)\n",
    "for n in range(1,26):\n",
    "    sleep(2)\n",
    "    driver.get(\"https://shop.wegmans.com/shop/categories/345?page=\" + str(n))\n",
    "    sleep(3)\n",
    "    items = driver.find_elements_by_css_selector(\".cell-title\")\n",
    "    for i in items:\n",
    "        items_extracted = i.text\n",
    "        wegmans_international_items.append(items_extracted)\n",
    "    sleep(randint(3,10))\n",
    "\n",
    "wegmans_intl_item_names = [i.split('\\n')[0] for i in wegmans_international_items]\n",
    "wegmans_intl_item_volumns = [i.split('\\n')[1] for i in wegmans_international_items]\n",
    "\n",
    "columns = {\n",
    "    'item_name': wegmans_intl_item_names,\n",
    "    'item_volumn': wegmans_intl_item_volumns\n",
    "}\n",
    "wegmans_intl = pd.DataFrame(data = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wegmans_intl_vect = count_vect.transform(wegmans_intl.item_name)\n",
    "wegmans_intl_tf = train_tf_transformer.transform(wegmans_intl_vect)\n",
    "\n",
    "X_intl = wegmans_intl_tf\n",
    "y_intl = log_reg.predict(X_intl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of East Asian food: 0.37\n",
      "Numbers of East Asian food items: 133\n"
     ]
    }
   ],
   "source": [
    "rate = round(len(y_intl[y_intl == 'asian']) / len(y_intl), 2) \n",
    "print('Proportion of East Asian food:', rate)\n",
    "print('Numbers of East Asian food items:', len(y_intl[y_intl == 'asian']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_volumn</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wegmans Organic Salsa, Medium</td>\n",
       "      <td>15.5 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wegmans Organic Mild Salsa</td>\n",
       "      <td>15.5 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kikkoman Soy Sauce, Less Sodium</td>\n",
       "      <td>10 fl. oz.</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Huy Fong Chili Sauce, Hot, Sriracha</td>\n",
       "      <td>17 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wegmans Reduced Sodium Soy Sauce</td>\n",
       "      <td>11.4 fl. oz.</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wegmans Organic Sesame Garlic Sauce</td>\n",
       "      <td>14 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wegmans Organic Teriyaki Sauce</td>\n",
       "      <td>14 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Old El Paso Enchilada Sauce, Red, Mild</td>\n",
       "      <td>10 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Wegmans Organic Black Bean Dip</td>\n",
       "      <td>16.5 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Wegmans Diced Green Chile Peppers</td>\n",
       "      <td>7 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Wegmans Whole Chipotle Peppers in Adobo Sauce</td>\n",
       "      <td>7 ounce</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Kikkoman Soy Sauce</td>\n",
       "      <td>10 fl. oz.</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        item_name   item_volumn   type\n",
       "10                  Wegmans Organic Salsa, Medium    15.5 ounce  asian\n",
       "12                     Wegmans Organic Mild Salsa    15.5 ounce  asian\n",
       "19                Kikkoman Soy Sauce, Less Sodium    10 fl. oz.  asian\n",
       "26            Huy Fong Chili Sauce, Hot, Sriracha      17 ounce  asian\n",
       "27               Wegmans Reduced Sodium Soy Sauce  11.4 fl. oz.  asian\n",
       "28            Wegmans Organic Sesame Garlic Sauce      14 ounce  asian\n",
       "35                 Wegmans Organic Teriyaki Sauce      14 ounce  asian\n",
       "36         Old El Paso Enchilada Sauce, Red, Mild      10 ounce  asian\n",
       "40                 Wegmans Organic Black Bean Dip    16.5 ounce  asian\n",
       "42              Wegmans Diced Green Chile Peppers       7 ounce  asian\n",
       "43  Wegmans Whole Chipotle Peppers in Adobo Sauce       7 ounce  asian\n",
       "45                             Kikkoman Soy Sauce    10 fl. oz.  asian"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Demo the identified food items\n",
    "wegmans_intl['type'] = y_intl\n",
    "wegmans_intl[wegmans_intl['type'] == 'asian'][:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harris Teeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_ht_pages(url, last_page_number):\n",
    "    list_of_items_ht = []\n",
    "    if last_page_number == 1:\n",
    "        driver.get(url)\n",
    "        sleep(randint(2,6))\n",
    "        elements = driver.find_elements_by_css_selector(\".product-name\")\n",
    "        for i in elements:\n",
    "            list_of_items_ht.append(i.text)\n",
    "        sleep(randint(2,6))\n",
    "        return list_of_items_ht\n",
    "    else:\n",
    "        for n in range(1, last_page_number+1):\n",
    "            driver.get(url + str(n) + \"&appliedSort=Brand\")\n",
    "            sleep(randint(2,6))\n",
    "            elements = driver.find_elements_by_css_selector(\".product-name\")\n",
    "            for i in elements:\n",
    "                list_of_items_ht.append(i.text)\n",
    "            sleep(randint(2,6))\n",
    "        return list_of_items_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different pages of Asian food\n",
    "canned_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,1557/products?isSpecialSubCategory=false\"\n",
    "ht_canned = scraping_ht_pages(canned_url, 1)\n",
    "\n",
    "noodles_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,976/products?pageNo=\"\n",
    "ht_noodles = scraping_ht_pages(noodles_url, 2)\n",
    "\n",
    "others_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,1558/products?isSpecialSubCategory=false\"\n",
    "ht_other = scraping_ht_pages(others_url, 1)\n",
    "\n",
    "sauces_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,912/products?pageNo=\"\n",
    "ht_sauces = scraping_ht_pages(sauces_url, 3)\n",
    "\n",
    "seasoning_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,1231/products?isSpecialSubCategory=false\"\n",
    "ht_seasoning = scraping_ht_pages(seasoning_url, 1)\n",
    "\n",
    "ramen_url = \"https://www.harristeeter.com/shop/store/332/category/583/subCategory/713,1164/products?pageNo=\"\n",
    "ht_ramen = scraping_ht_pages(ramen_url, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "harris_teeter_asian = ht_canned + ht_noodles + ht_other + ht_sauces + ht_seasoning + ht_ramen\n",
    "ht_asian = pd.Series(harris_teeter_asian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_asian_vect = count_vect.transform(harris_teeter_asian)\n",
    "ht_asian_tf = train_tf_transformer.transform(ht_asian_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ht = ht_asian_tf\n",
    "y_ht = log_reg.predict(X_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of East Asian food: 0.65\n",
      "Numbers of East Asian food items: 88\n"
     ]
    }
   ],
   "source": [
    "rate_ht = round(len(y_ht[y_ht == 'asian']) / len(y_ht), 2) \n",
    "print('Proportion of East Asian food:', rate_ht)\n",
    "print('Numbers of East Asian food items:', len(y_ht[y_ht == 'asian']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sharwood's Curry Cooking</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Annie Chuns Maifun Brown Rice Noodles</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Annie Chuns Noodle Soup - Miso with Tofu and S...</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hakubaku Organic Ramen Noodles</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KA ME Rice Sticks</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ka-Me Pad Thai Express Rice Noodles</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ka-Me Thai Rice Noodles - Stir Fry</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>La Choy Rice Noodles</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Maruchan Ramen Noodle Soup, Gold, Spicy Miso F...</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tasty Bite Rice, Organic, Smoky Chipotle</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            item_name   type\n",
       "7                            Sharwood's Curry Cooking  asian\n",
       "9               Annie Chuns Maifun Brown Rice Noodles  asian\n",
       "10  Annie Chuns Noodle Soup - Miso with Tofu and S...  asian\n",
       "16                     Hakubaku Organic Ramen Noodles  asian\n",
       "17                                  KA ME Rice Sticks  asian\n",
       "19                Ka-Me Pad Thai Express Rice Noodles  asian\n",
       "22                 Ka-Me Thai Rice Noodles - Stir Fry  asian\n",
       "24                               La Choy Rice Noodles  asian\n",
       "25  Maruchan Ramen Noodle Soup, Gold, Spicy Miso F...  asian\n",
       "28           Tasty Bite Rice, Organic, Smoky Chipotle  asian"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## demo the East Asian food items\n",
    "frames = {\n",
    "    'item_name': ht_asian,\n",
    "    'type': y_ht\n",
    "}\n",
    "ht_asian = pd.DataFrame(data=frames)\n",
    "ht_asian[ht_asian['type'] == 'asian'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the selection of International Food between the two supermarkets, Wegmans has more East Asian items (133) compared to Harris Teeter (88). \n",
    "I'll visit Harris Teeter first because it'll be more efficient "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
